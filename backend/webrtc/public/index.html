<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <title>WebRTC Demo</title>
    <link rel="icon" href="data:,">
    <style>
        body {
            margin: 0;
            padding: 20px;
            background: #1a1a1a;
            color: white;
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
        }

        .video-container {
            position: relative;
            margin: 15px;
            border-radius: 12px;
            overflow: hidden;
            transition: border 0.3s ease;
            border: 3px solid #333;
        }

        .video-container.speaking {
            border-color: #00ff88;
            box-shadow: 0 0 20px rgba(0, 255, 136, 0.5);
        }

        .video-container video {
            width: 400px;
            height: 300px;
            background: #000;
            display: block;
        }

        .video-label {
            position: absolute;
            top: 10px;
            left: 10px;
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 5px 10px;
            border-radius: 15px;
            font-size: 14px;
            font-weight: bold;
        }

        .videos-section {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 20px;
            margin-bottom: 30px;
        }

        .controls {
            display: flex;
            gap: 15px;
            background: rgba(255, 255, 255, 0.1);
            padding: 15px 25px;
            border-radius: 25px;
            backdrop-filter: blur(10px);
        }

        .control-btn {
            background: #333;
            border: none;
            color: white;
            padding: 12px 18px;
            border-radius: 50%;
            cursor: pointer;
            font-size: 18px;
            transition: all 0.3s ease;
            width: 50px;
            height: 50px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .control-btn img {
            width: 24px;
            height: 24px;
            filter: brightness(0) invert(1);
        }

        .control-btn:hover {
            background: #555;
            transform: scale(1.1);
        }

        .control-btn.active {
            background: #00ff88;
            color: #000;
        }

        .control-btn.active img {
            filter: brightness(0);
        }

        .control-btn.muted {
            background: #ff4757;
        }

        .control-btn.muted img {
            filter: brightness(0) invert(1);
        }

        .control-btn.danger {
            background: #ff4757;
        }

        .control-btn.danger:hover {
            background: #ff3742;
        }

        .room-info {
            margin-bottom: 20px;
            font-size: 16px;
            opacity: 0.8;
        }
    </style>
</head>

<body>
    <div class="room-info">
        Room: <span id="roomDisplay"></span> |
        Duration: <span id="callTimer">00:00</span>
    </div>

    <div class="videos-section">
        <div class="video-container" id="localContainer">
            <video id="localVideo" autoplay playsinline muted></video>
            <div class="video-label" id="localLabel">You</div>
        </div>

        <div class="video-container" id="remoteContainer">
            <video id="remoteVideo" autoplay playsinline></video>
            <div class="video-label" id="remoteLabel">Connecting...</div>
        </div>
    </div>

    <div class="controls">
        <button class="control-btn active" id="muteBtn" title="Mute/Unmute">
            <img src="assets/icons8-microphone-48.png" alt="Microphone">
        </button>
        <button class="control-btn active" id="videoBtn" title="Camera On/Off">
            <img src="assets/icons8-camera-24.png" alt="Camera">
        </button>
        <button class="control-btn danger" id="endBtn" title="End Call">
            <img src="assets/icons8-call-button-24.png" alt="End Call">
        </button>
    </div>

    <script>
        // Get room ID and role from URL parameters
        const urlParams = new URLSearchParams(window.location.search);
        const roomId = urlParams.get('room') || 'default';
        const userRole = urlParams.get('role') || 'user';

        // Connect to WebSocket with room parameter - use secure protocol for HTTPS
        const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
        const ws = new WebSocket(`${protocol}//${location.host}?room=${roomId}`);
        const pc = new RTCPeerConnection({
            iceServers: [{ urls: "stun:stun.l.google.com:19302" }]
        });

        // Display room info and user role
        document.title = `WebRTC Demo - Room: ${roomId}`;
        document.getElementById('roomDisplay').textContent = roomId;
        document.getElementById('localLabel').textContent = userRole === 'student' ? 'Student (You)' : userRole === 'tutor' ? 'Tutor (You)' : 'You';

        const localVideo = document.getElementById("localVideo");
        const remoteVideo = document.getElementById("remoteVideo");
        const localContainer = document.getElementById("localContainer");
        const remoteContainer = document.getElementById("remoteContainer");

        // Control elements
        const muteBtn = document.getElementById("muteBtn");
        const videoBtn = document.getElementById("videoBtn");
        const endBtn = document.getElementById("endBtn");

        // Track states
        let isAudioEnabled = true;
        let isVideoEnabled = true;
        let localStream = null;
        let callStartTime = null;
        let elapsedSeconds = 0;
        let timerInterval = null;

        // Timer and messaging functions
        function startCallTimer() {
            callStartTime = Date.now();

            // Send session started event (critical event #1)
            sendMessageToParent({
                type: 'session-started',
                sessionId: roomId,
                participants: [userRole, userRole === 'student' ? 'tutor' : 'student'],
                timestamp: callStartTime
            });

            timerInterval = setInterval(() => {
                elapsedSeconds = Math.floor((Date.now() - callStartTime) / 1000);

                // Update display
                const minutes = Math.floor(elapsedSeconds / 60);
                const seconds = elapsedSeconds % 60;
                document.getElementById('callTimer').textContent =
                    `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;

                // Send to parent for billing (critical event #2)
                sendMessageToParent({
                    type: 'timer-update',
                    sessionId: roomId,
                    elapsedSeconds: elapsedSeconds,
                    timestamp: Date.now()
                });
            }, 1000);
        }

        function sendMessageToParent(data) {
            if (window.parent !== window) {
                window.parent.postMessage(data, '*');
            }
            // Also log for debugging
            console.log('Sent to parent:', data);
        }

        function endCallTimer() {
            if (timerInterval) {
                clearInterval(timerInterval);
                timerInterval = null;
            }

            // Send session ended event (critical event #4)
            sendMessageToParent({
                type: 'session-ended',
                sessionId: roomId,
                totalSeconds: elapsedSeconds,
                endedBy: userRole,
                timestamp: Date.now()
            });
        }

        // Capture camera + mic
        async function initializeMedia() {
            try {
                // Check if we're in a secure context
                if (!window.isSecureContext && location.protocol !== 'https:' && location.hostname !== 'localhost') {
                    throw new Error('HTTPS is required for camera/microphone access. Please access this page over HTTPS.');
                }

                // Check if getUserMedia is available
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    throw new Error('Your browser does not support camera/microphone access.');
                }

                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                localStream = stream;
                localVideo.srcObject = stream;
                stream.getTracks().forEach(track => pc.addTrack(track, stream));
                setupAudioLevelDetection(stream, localContainer);

                // Send user connected event
                sendMessageToParent({
                    type: 'user-connected',
                    sessionId: roomId,
                    userRole: userRole,
                    timestamp: Date.now()
                });
            } catch (error) {
                console.error('Error accessing media devices:', error);

                let errorMessage = 'Camera/microphone access failed: ';
                if (error.name === 'NotAllowedError') {
                    errorMessage += 'Permission denied. Please allow camera and microphone access and refresh the page.';
                } else if (error.name === 'NotFoundError') {
                    errorMessage += 'No camera or microphone found. Please check your devices.';
                } else if (error.name === 'NotSupportedError') {
                    errorMessage += 'Camera/microphone not supported in this browser.';
                } else if (error.message.includes('HTTPS')) {
                    errorMessage = error.message;
                } else {
                    errorMessage += error.message;
                }

                alert(errorMessage);
                document.getElementById('remoteLabel').textContent = 'Media Access Failed';
            }
        }

        initializeMedia();

        // 2️⃣ Display remote stream
        pc.ontrack = (event) => {
            remoteVideo.srcObject = event.streams[0];
            document.getElementById('remoteLabel').textContent = userRole === 'student' ? 'Tutor' : userRole === 'tutor' ? 'Student' : 'Remote User';
            setupAudioLevelDetection(event.streams[0], remoteContainer);

            // Start billing timer when both parties are connected
            if (!callStartTime) {
                startCallTimer();
            }
        };

        // Audio level detection for speaking indicator
        function setupAudioLevelDetection(stream, container) {
            const audioContext = new AudioContext();
            const analyser = audioContext.createAnalyser();
            const microphone = audioContext.createMediaStreamSource(stream);
            const dataArray = new Uint8Array(analyser.frequencyBinCount);

            microphone.connect(analyser);
            analyser.fftSize = 256;

            function checkAudioLevel() {
                analyser.getByteFrequencyData(dataArray);
                const average = dataArray.reduce((a, b) => a + b) / dataArray.length;

                if (average > 15) {
                    container.classList.add('speaking');
                } else {
                    container.classList.remove('speaking');
                }

                requestAnimationFrame(checkAudioLevel);
            }

            checkAudioLevel();
        }

        // 3️⃣ Send ICE candidates
        pc.onicecandidate = (event) => {
            if (event.candidate) {
                ws.send(JSON.stringify({ type: "ice", candidate: event.candidate }));
            }
        };

        // 4️⃣ Handle incoming signaling messages
        ws.onmessage = async (event) => {
            let data = event.data;
            if (data instanceof Blob) {
                data = await data.text();
            }
            const msg = JSON.parse(data);

            if (msg.type === "offer") {
                await pc.setRemoteDescription(new RTCSessionDescription(msg.offer));
                const answer = await pc.createAnswer();
                await pc.setLocalDescription(answer);
                ws.send(JSON.stringify({ type: "answer", answer }));
            } else if (msg.type === "answer") {
                await pc.setRemoteDescription(new RTCSessionDescription(msg.answer));
            } else if (msg.type === "ice") {
                try { await pc.addIceCandidate(msg.candidate); } catch (e) { }
            }
        };

        // 5️⃣ Create offer if first peer
        ws.onopen = async () => {
            // Wait 1 sec to see if other peer connects
            setTimeout(async () => {
                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);
                ws.send(JSON.stringify({ type: "offer", offer }));
            }, 1000);
        };

        // Control button functionality
        muteBtn.addEventListener('click', () => {
            if (localStream) {
                const audioTrack = localStream.getAudioTracks()[0];
                if (audioTrack) {
                    audioTrack.enabled = !audioTrack.enabled;
                    isAudioEnabled = audioTrack.enabled;
                    muteBtn.classList.toggle('active', isAudioEnabled);
                    muteBtn.classList.toggle('muted', !isAudioEnabled);

                    // Log action for parent
                    sendMessageToParent({
                        type: 'user-action',
                        action: isAudioEnabled ? 'unmuted' : 'muted',
                        sessionId: roomId,
                        userRole: userRole,
                        timestamp: Date.now()
                    });
                }
            }
        });

        videoBtn.addEventListener('click', () => {
            if (localStream) {
                const videoTrack = localStream.getVideoTracks()[0];
                if (videoTrack) {
                    videoTrack.enabled = !videoTrack.enabled;
                    isVideoEnabled = videoTrack.enabled;
                    videoBtn.classList.toggle('active', isVideoEnabled);
                    videoBtn.classList.toggle('muted', !isVideoEnabled);

                    // Log action for parent
                    sendMessageToParent({
                        type: 'user-action',
                        action: isVideoEnabled ? 'video-enabled' : 'video-disabled',
                        sessionId: roomId,
                        userRole: userRole,
                        timestamp: Date.now()
                    });
                }
            }
        });

        endBtn.addEventListener('click', () => {
            if (confirm('End the call?')) {
                endCallTimer();

                if (localStream) {
                    localStream.getTracks().forEach(track => track.stop());
                }
                pc.close();
                ws.close();
                window.close();
            }
        });
    </script>
</body>

</html>